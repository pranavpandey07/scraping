{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting with chrome webdriver and feeding in the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insering the values in search bar of skill and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_des=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'input[id=\"qsb-keyword-sugg\"]')))\n",
    "loc=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'input[id=\"qsb-location-sugg\"]')))\n",
    "\n",
    "skill_des.clear()\n",
    "loc.clear()\n",
    "skill_des.send_keys(\"Data Analyst\")\n",
    "loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pressing the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'button[class=\"btn\"]'))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the empty lists for attributes of resultant dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_profile=[]\n",
    "location=[]\n",
    "company_name=[]\n",
    "exp_req=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seaching for different attributes like job_profile , experience required,location and company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "exper=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loca=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "company=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using for loop to add the values in empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in loca:\n",
    "    x=i.text\n",
    "    location.append(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in company:\n",
    "    x=i.text\n",
    "    company_name.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in profile:\n",
    "    x=i.text\n",
    "    job_profile.append(x)\n",
    "    \n",
    "\n",
    "    \n",
    "for i in exper:\n",
    "    x=i.text\n",
    "    exp_req.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing the lists to only contain 10 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_profile=job_profile[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "location=location[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name=company_name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_req=exp_req[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataframe with our lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naukri=pd.DataFrame({\"Company Name\":company_name,\"Location\":location,\"Designation\":job_profile,\"Experience Required\":exp_req})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Senior Specialist - Data Analyst</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGI Information Systems and Management Consult...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Business/Data Analyst - SSE/LA</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Infobahn Softworld Inc.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Business Data Analyst II</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WEIWO Communication Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru(Ulsoor)</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>India Medtronic Pvt. Ltd,.</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>Data Analyst/Business Analyst-Gurgaon/Bangalor...</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMEDC SERVICES PRIVATE LIMITED</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name  \\\n",
       "0                              Philips India Limited   \n",
       "1  CGI Information Systems and Management Consult...   \n",
       "2                            Infobahn Softworld Inc.   \n",
       "3                      WEIWO Communication Pvt. Ltd.   \n",
       "4                                   Trigent Software   \n",
       "5                                   Trigent Software   \n",
       "6                         India Medtronic Pvt. Ltd,.   \n",
       "7                     SMEDC SERVICES PRIVATE LIMITED   \n",
       "8                   Allegis Services India Pvt. Ltd.   \n",
       "9                   Allegis Services India Pvt. Ltd.   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                        Bangalore/Bengaluru(Ulsoor)   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                 (WFH during Covid)   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                         Designation Experience Required  \n",
       "0                   Senior Specialist - Data Analyst             4-8 Yrs  \n",
       "1                     Business/Data Analyst - SSE/LA             2-5 Yrs  \n",
       "2                           Business Data Analyst II             5-8 Yrs  \n",
       "3                                       Data Analyst             4-8 Yrs  \n",
       "4                              Business Data Analyst             3-5 Yrs  \n",
       "5                              Business Data Analyst             3-5 Yrs  \n",
       "6  Data Analyst/Business Analyst-Gurgaon/Bangalor...             1-4 Yrs  \n",
       "7                                Senior Data Analyst             5-8 Yrs  \n",
       "8                                       Data Analyst             2-5 Yrs  \n",
       "9                                       Data Analyst             3-5 Yrs  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_naukri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "\n",
    "Note- 1. All of the above steps have to be done in code. No step is to be done manually.\n",
    "\n",
    "      2.Please note that you have to scrape full job description. For that you may have to open each job separately as shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating an empty list job_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_url=[]\n",
    "url=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a for loop to add values to job_url from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url:\n",
    "    x=i.get_attribute('href')\n",
    "    job_url.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an empty list of job description and extracting information from website and adding to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  Managing and ensuring data quality, integrity, normalization and accuracy of available datasets. Improve data quality as per data quality framework and working with data owner. Internal and external benchmarking to establish things influencing data quality.\\nManaging and designing the reporting environment, including data sources, security, and metadata. Generate business insights using BI dashboards that shall provide clear directions/actions to senior managers to support decision-making.\\nSupport digitization to improve quality of data. Root cause analysis by using quality analysis tools, machine learning and statistics.\\nHelping organization to take key decisions based on integrated analytics involving different datasets. Perform predictive data analysis, generate indications for focus area and target the improvements proactively.\\nMaintain and re-engineer existing ETLs to increase data accuracy, data stability, and pipeline performance.\\nAdvanced statistical techniques for complex data analysis. Interpreting data, analysing results using statistical techniques, developing analytical reports.\\nAdherence to compliance procedures in accordance with regulatory standards, requirements, and policies. Managing and designing the reporting environment, including data sources security, and metadata.\\nSufficient business acumen to understand business objectives & dynamics\\nJob Qualifications:\\nBachelor s or masters degree in Computer Science, Information management, Statistics or related field\\n10+ years of experience in the Consumer or Healthcare industry in an analytical role with focus on querying data, analyzing and clearly presenting analyses to stakeholders across the organization.\\nWorking experience on Python, R Programming, Scala, Apache Spark, AWS Redshift is must.\\nMandatory working experience in QlikView, Adobe analytics, Google 360. Knowledge in analytics tools like Tableau, Power BI, Excel VBA Macros, RSPSS, SAS is an added advantage.\\nProven working experience as a data analyst or business data analyst. Experience in working on Business intelligence tools/platforms and systems.\\nStrong knowledge in data pre-processing and EDA by using various tools. Thorough in analytics/visualization tool setup, configuration and administration.\\nHaving knowledge of classification (Random Forest, SVM, Boosting and Bagging techniques) and clustering algorithms is desirable\\nHands on in Descriptive / Predictive / Prescriptive Analytical techniques. Ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy\\nResults driven with analytical and numeric skills. Convey data story through the visualization.\\nA team player capable of working and integrating across cross-functional team for implementing project requirements. Experience in technical requirements gathering and documentation.\\nAbility to work effectively and independently in a fast-paced agile environment with tight deadlines\\nA flexible, pragmatic and collaborative team player with innate ability to engage with stakeholders at all levels in the organization.',\n",
       " 'Company systems organization structure, system data maintenance and management\\nManagement of system equipment authority , Account number and master data\\nInformation system, operation and application guidance , Data check, Data analysis\\nPreparing Daily, Weekly & Monthly MIS Reports\\nPreparing presentations, Graphs and analytical reports\\nMarket Visit based on requirements\\nCo-Ordinate with the team as well as the Zone Head for reports.\\nCoordination with different team members to collate data\\nKeep track of the Promoters Sales & Incentive.\\nHelp the team with all other reports.\\nRequired Candidate profile\\n\\nCandidate should fluency in English and Kannada\\nPreferable candidate Advance Excel VBA & Macros, SQL\\nExcellent Communication & Interpersonal Skills\\nProficient in using MS Office including Word, PowerPoint,\\nTime Management ,Problem Solving Skills,\\nAbility to multitask proactively\\nAnalytical thinking and problem solving',\n",
       " 'Dear Candidates\\n\\nWe have a Immediate requirement of Business Data Analyst for one of our Client at Bangalore Location.\\n\\nSummary\\nLocation: Bangalore\\nExperience: 3 to 5  years experience level is required.\\nPosition:  Business Data Analyst\\nImmediate joiners preferred within 15 days joiners acceptable.\\n\\nJD for Business Data Analyst:\\n\\nDescription:\\nEIM (Entitlement and Install Base Master) Business Data Analysts work as part of a team that supports and enhances Client business processes and Data Quality. You will utilize your strong technical competencies and functional business expertise to identify, evaluate and develop processes and procedures that meet business requirements. To do this successfully, you will work closely with cross-functional teams to understand business needs and drive data quality improvement projects. An ability to understand business process issues and communicate technical solutions is essential to your success in this role\\nEssential Functions:\\n• Data Analysis:\\n- Provide information and analysis essential for data quality improvements, Sales & Renewal planning and strategy development\\n- Aggregating and organizing information from multiple data sources to aid in analysis\\n- Manage analytical projects to deliver intelligence and data discovery capabilities\\n- Run statistical analysis on Client Customer Install Base (IB) data\\n- Analyze and review existing data to ensure maximum quality\\n• Data Management:\\n- Provide transactional support to Client enterprise systems\\n- Work closely with key business users to identify data gaps and needs\\n- Provide support for projects as required, including participating in system enhancements\\n- Manage IB registration business logic, data mapping, and data transformation logic\\n- Respond to escalations related to Customer IB data and facilitate cross-team resolution\\nResponsibility:\\nTrack, Monitor, Analyze, Root Cause & Resolve Customer IB & Contract data registration failures\\n• Build, Execute and Publish EIM DQ and BVAL metrics on a weekly basis for management and stakeholders review\\n• Sharing weekly and monthly metrics with stakeholders, senior management and internal around all operational activities managed by EIM Operations\\n• Responsible for monitoring EIM inbound and outbound events to ensure transactions are flowing smoothly\\n• Support all Customer IB data related requests coming through Service Now tool\\n• Build and maintain Process documents for activities managed by EIM Ops\\nRequirements:\\n• Experience with relational database (i.e., Oracle, SQL Server and Access) with the ability to write SQL queries to develop reports from scratch and utilize existing report templates\\n• Zeal to get hands on into data and perform multiple ad hoc analysis in SQL and/or analytics tools as required\\n• Data profiling skills using SQL or other tools. Experience with the Oracle SQL Developer environment is a plus. Must be able to demonstrate data analysis skills in interview.\\n• 3+ years in a business/data analyst role. Must be a well versed with SQL and data analysis\\n• Ability to interact with Business and Technology units, understanding processes and enabling requirements. Must also be able to create PowerPoint documents and be comfortable presenting to executive management.\\n• Previous experience working with regulatory projects with large volume data analysis efforts preferred. Ability to document and effectively communicate information requirements and objectives for a major project or multiple lesser projects\\n• Must be able to lead and influence technology and business partners on multiple projects or enhancements and Liaise with multiple groups (Business and Technology) to understand and drive implementation changes as part of data governance and analysis efforts\\n• Participate in business requirements discussion, documentation and validation\\n• Must be deadline oriented, able to identify risks and resolve issues\\nEducation & Experience:\\n• Bachelors Degree is required\\n• 3 to 5 years of enterprise experience in data management and reporting applications, preferably with high tech companies\\n\\nRegards\\nNaveen Kumar N\\nMail id: naveen_k@trigent.com\\nContact no: 9108228912 (Call between 9:30 Am to 6:30 Pm on weekdays only)',\n",
       " 'Position Title: Service Data & Contract Analyst Service and Repair\\n\\nDivision: Service & Repair\\n\\nPosition Summary (brief Summary of job purpose)\\nThe Service Data & Contract Analyst role is responsible for growing service revenue in general and contract revenue in particular by partnering with field service engineers, Depot Service Engineers, and customers across the full range of serviceable products in entire ISC region. The role is responsible for designing contracts to meet customer requirements, reviewing, and amending terms and conditions of customer contracts, providing timely market trends, providing service expertise to operating units and proactively enabling relevant teams to sell service agreements.\\n\\nPosition Responsibilities:\\nSupport the growth of service contract uptake through clear value propositions linked to the various tiered contract offerings.\\nMarket analysis & Business development\\nOpportunity management & Forecasting (SFDC)\\nAdminister, extend and negotiate standard and non-standard contracts including completing the red-line/editing process to meet customer specifications, and partnering with Legal where appropriate.\\nDevelop creative service and/or pricing solutions to address complex hospital scenarios.\\nPeriodically review and revise contract pricing, partnering with internal teams. Collaborate cross-functionally to determine annual list prices and other pertinent issues involving service revenue.\\nParticipate in contract negotiations (within approved pricing parameters) with field employees with minimal supervisory involvement. Ensure the sales team is updated on significant customer related issues regarding service and brainstorm solutions.\\nCollaborate with Sales and Service teams to strategically target and forecast monthly and quarterly sales and for long term funnel management. Regularly update and maintain opportunities to reflect their point in the sales stage and probability of closing.\\nMaintain customer files and complete and accurate information in various customer databases, including Salesforce.com and SAP.\\nAnalyse break fix (time and material) repair history and qualify new opportunities to convert customers to contract. Review install base records, consumable usage patterns and other data to identify new opportunities to convert customers to contract.\\nCreate presentations demonstrating the value of contracted services to internal operating units, commercial overlays, and key external customers.\\nSupport contract negotiations involving hospital group purchasing contracts, across multiple Medtronic businesses, as appropriate.\\nCollaborate with various commercial teams to respond to service requests in capital equipment tenders.\\nProvide other sales support as necessary related to Services.\\nDevelop and lead continuous improvement projects that drive profitable growth and commercial excellence.\\nAll activities must be performed in compliance with the Quality System.\\nPerforms duties in compliance with environmental, health and safety related site rules, policies or governmental regulations.\\n\\nJOB QUALIFICATIONS\\nREQUIREMENTS PREFERENCES\\nBSc /BE /B Tech/MBA Degree\\nA total of at least 4 years (or more) in Data analysis & management domain\\nExperience in medical device industry\\nExperience in strategy consulting and implementation\\n\\nSKILLS/COMPETENCIES\\nAbility to analyse and negotiate complex service agreements\\nExcellent communication skills both oral and written.\\nStrong organization skills and able to effectively prioritize daily work demands.\\nResponsive, confident problem solver.\\nWillingness to work in a team environment including working with field Sales Professionals with a high sense of urgency.\\nExperience in SAP is must.\\nExperience with SalesForce.com.\\nExperience working in Excel.\\n\\n\\nInterested candidates may apply at aarushi.a@medtronic.com',\n",
       " 'Job Overview\\nWe are looking for a hands-on, detail oriented and highly motivated Senior Data Analyst to help create data backed insights that will drive improvement for business impact. He/She should be focused and having passion for both math and technology to join our growing Data Science team. This group writes the math and software to unlock the value in data assets while creating new and unique offerings for customers.\\nIn this role, you will have the opportunity to work directly with the business innovation teams, marketing, sales and global customers along with expertise from Ecolabs Center for Advanced Analytics, to develop the data strategy and advanced analytics pipeline.\\nOpportunity to stay on the cutting edge of research and then to put this research to practical use by building your own software systems. You will be able to see the results of your efforts ripple throughout our systems in real-time. You will design your systems as you see fit, own your code, and your work will have a very direct, measurable impact on our core metrics.\\nResponsibilities\\nBuild compelling, clear and powerful visualizations of data.\\nDesign, architect and implement interactive dashboards and reports.\\nDevelop a common language and approach to analyzing and communicating information and insights across teams.\\nA problem-solving mindset with the ability to understand business challenges and how to apply analytics expertise to solve them.\\nshould be comfortable interfacing with technology systems and be able to analyze data and gather actionable conclusions.\\nOperating in a rapidly changing environment will require the candidate to be adept at dealing with ambiguous, new and challenging situations.\\nThe candidate will be comfortable in executing repeatable processes.\\nThe unique person who can present complex mathematical solutions in a simple manner that most will understand, including customers.\\nAn individual excited by innovation and new technology and eager to finds ways to employ these innovations in practice.\\nA team mentality empowered by the ability to work with a diverse set of individuals.\\nTell a clear story, highlight insights we had not previously seen and do it all faster than we’ve been able to previously.\\nCreate, maintain and document a robust set of metrics to monitor day-to-day bug detection and long-term performance tracking.\\nHave strong understanding of best practices, standards and guidelines in each technology/product and apply same to produce high quality deliverables\\nShould be able to take responsibility for the software life cycle - set up all environment, design, code, test, repository mgmt and deployments as applicable and as required.\\nRequired Qualifications\\nA Bachelor’s degree in Data Analysis, Math, Statistics, Computer Science or related field with an emphasis on analytics.\\n5+ Years professional experience in a data scientist/analyst role or similar.\\nProven ability at design and building scalable, high-performance data visualization using PowerBI, D3JS, c3js, Angular, Tableau preferably PowerBI.\\nProficiency in statistics/analytics preferably in the Microsoft Azure Suite, including Azure ML Studio, ADF, Data Lake, HDI and SQL.\\nPython, ML libraries, Jupiter Notebook, Anaconda, ML concept, Power BI\\nFamiliarity with significance testing, sampling, descriptive statistics, Bayesian models & multivariate statistics\\nPreferred Qualifications\\nPrior experience with machine learning algorithms and their implementations\\nExperience with manipulating large data sets, working with parquet files.\\nDeep Leaning, Computer Vision, NLP Concepts and frameworks.\\nDocker/Kubernetes, Kubeflow, PySpark\\nExposer to NOSQL concepts.\\nExcellent communication, organizational transformation, and leadership skills\\nDemonstrated excellence in Data Science, Business Analytics and EngineeringRoles and Responsibilities\\n\\n\\nDesired Candidate Profile\\n\\n\\nPerks and Benefits',\n",
       " 'We are looking for data analyst with experience in credit & finance solutions ,preferably worked on analytical and reporting solution\\nPOWER BI SKILLS\\n-Responsibility of resource include requirement gathering from Business\\n-Proposing efficient solutions to Business\\n-Contributes to Design of solution in collaboration with solution architect , Sr Designers\\n- Collaborates with data architect for data modelling\\n- Testing solution post build\\n- Experience with SQL-based technologies (e.g. MSSQL, MySQL, PostgreSQL) is preferred .\\n-Resource should have good communication /stakeholder management skills',\n",
       " '1. Azure Analytics (Preferred)\\n2. SQL (Preferred)\\n3. Power BI (Preferred)\\n4. Natural Language Processing (Added Advantage)\\n5. Python (Added Advantage)\\nPrimary skills:\\nAzure, Databricks 3+ years Azure Advanced Analytics\\nSQL Server Analysis Services\\nPowerBI (Analyzing and Visualizing Data with Microsoft Power BI) Certified PowerBI\\nThe Data Analyst is responsible for identifying, analyzing and documenting the business needs. Helping the business to find the right answer to solve their business problems, to determine feasible solutions contributing to develop new business models. Equally this role is about providing support to the business to further professionalize their MI / Analytic reporting platform, using the ESSA approach [Automate, Standardize, Simplify & Automate]\\nPrecisely capture business problems, value drivers, and functional/non-functional requirements, including health, safety, security, usability, data, and supportability considerations.\\nTranslate business requirements into functionality and assess the risks, feasibility, opportunities, and business impacts of various solution options.\\nAssess and model processes, data flows, and technology to understand the bottlenecks and identify opportunities for improvement.\\nCreate clear documentation to communicate requirements and related information; keep updated to align with the solution over the project lifecycle.\\nEnsure traceability of requirements from business needs and requirements, through testing and scope changes, to final solution.\\nInteract with software suppliers, designers and developers to understand software limitations, deliver elements of system and database design, and ensure that business requirements and use.',\n",
       " 'The responsibilities of the Data Engineer (Technical) include managing the day-to-day activities for the Data Analytics and Visual Analytics driven business solutions of the customer. This includes\\n\\n1. Administration of the reporting solution built using Tableau, Excel, VBA Macro and Queries are written using PL/SQL\\n2. Managing reporting incidents and requests within the specified SLA\\n3. Modification of existing reports and PL/SQL codes\\n4. Supporting & Coordinating with business and technical team\\n5. Automation of daily jobs wherever possible\\n6. Analysis of data as per compliance\\n7. New report development using Tableau and/or PL/SQL on demand basis\\n8. Daily health checks and housekeeping activities\\n\\nRequired Skills:\\nVery Good Excel skills – Macros and VBA/ VB\\nStrong in PL/SQL queries and Database Systems\\nStrong MS Office Skills (mainly excel) and proficient in writing Macros (VB Skills)\\nAlso good in Python for data management\\nExperience in BI report building using Tableau\\n\\nA minimum of 6 years of experience in IT / Data Analytics industry out of that 2 years in the field of Data Analytics as has been mentioned under responsibilities above',\n",
       " 'Works independently under limited supervision and applies knowledge of subject matter in Applications Development. Possess sufficient knowledge and skills to effectively deal with issues, challenges within field of specialization to develop simple applications solutions. Second level professional with direct impact on results and outcome\\nRequired qualifications/Skills\\nExperience to be successful in this role Data/Business Analyst with work experience in Banking Domain(Lending, trading, inventory portfolios & regulatory risk reports)\\nStrong data analysis and problem solving skills including use of SQL for querying and joining data\\nExperience working in Risk Data Management i.e. risk data such as SN exposure aggregation, TNX, facility matching, etc.\\nExposure to Data Warehousing concepts(ETL & Reporting)\\nNice to have skills on Teradata\\n\\nTechnologies required: / Selected Skills\\n\\nTechnical:\\nDatabase(Teradata), SQL\\n\\nDomain : Banking((Lending, trading, inventory portfolios & regulatory risk reports)\\nSkills:\\nBanking\\nETL\\nRisk Management / Analysis\\nSQL\\nTeradata',\n",
       " 'Role : Senior Data Analyst\\n\\nRequired Skills :\\n\\n- Masters or Bachelors in Science or Technology domain\\n\\n- 6+ years of experience in managing Data, Analytics and Reporting\\n\\n- Extensive experience in writing database queries across SQL and NoSQL databases like Oracle, MongoDB\\n\\n- Experience in managing, querying, and reporting Data warehouses like AWS Redshift\\n\\n- Experience in using BI tools like Looker, Tableau, Cognos\\n\\n- Experience in Data extraction, classification, and reporting\\n\\n- Experience in designing Data models, relationships, and logical diagrams\\n\\n- Experience in Insurance Domain will be a strong advantage\\n\\n- Must have good attitude and excellent communication skills\\n\\n- Must be willing to work from 4 p.m. to 12 a.m. IST to overlap working hours with US-based Client',\n",
       " 'Key Responsibilities:\\nAct as a data gatekeeper for new leads and accounts in the database. Validate the data through de-duplication, source validation and enrichment of fields (such as no. of employees, revenue, industry, segment) on all applicable records using Qlik’s various Data Tools.\\nEnsure that the new records are enriched accurately and within agreed SLAs (24hrs for all new inbound leads)\\nContribute to best practices in data capture\\nDatabase quality and augmentation\\nCollaboration with extended teams and flexibility to support key projects\\nAttention to detail and ability to be flexible with day-to-day marketing priorities\\nKey Stakeholders\\nGlobal Operations\\nInside Sales/Business Development\\nSales & Marketing Teams\\nCompetencies and skills:\\nDesirable: Knowledge of Salesforce.com, Previous Data Analyst experience\\nKnowledge of DemandTool or alike\\nBasic knowledge of Marketo or Eloqua\\nKnowledge in MS Office (Excel primarily)\\nReporting and analysis\\nAbility to demonstrate analytical and problem solving skills\\nAbility to turn around data enrichment work quickly and accurately\\nProven ability to prioritize, work independently within a fast-paced environment\\nExcellent verbal and written communication skills\\nAttention to detail\\nOther (mandatory) requirements:\\n2 years of experience in database operations or administration\\nGood communication\\nTime management and flexibility\\nAnalytical bent of mind\\nQualifications:\\nBachelor’s degree',\n",
       " 'What You Will Do\\nCreate business impact by working on strategic initiatives in GoFood focussed on analysis and experimentation\\nDeliver insight, analysis using statistical tools, data visualization, and business use case to product and business teamPerform analysis in relation to determining new project pilot settings, new features, user behavior, and in-app behavior\\nBuild maintain dashboards for tracking business performance and product adoption Partner with Lead or Senior Analyst to help Product Managers and Business teams create decision-based on decision science\\nPartner with Lead or Senior Analyst in identifying product or business opportunities and support in product delivery such as experimentation\\nBuild first cut Machine Learning models based on product requirementsCreate and automate data extraction by creating denormalized tables\\nWhat You Will Need\\n2+ years of experience with basic statistics or product analytics along with strong business acumen\\nExpert in SQL and strong experience with a data visualization and dashboarding tool (e.g. Tableau, Metabase, Google Data Studio, Clevertap, Python, etc)\\nExposure in working with Machine Learning (forecasting, clustering, statistical significance test, predictive modeling, and text mining) is a plus\\nExperience in helping Product Team or Business team to deliver products as end-to-end data solutions (from data pipelining to analysis, presenting, and scalable adaption)\\nComfortable working with minimal guidance and in a team setting\\nAbility to use critical thinking daily to manage daily tasks while being goal-orientedAbility to transform an ambiguous business or product problem into a well-scoped and impactful analysis; able to design simple experiments',\n",
       " 'What You Will Do\\nCreate business impact by working on strategic initiatives in GoFood focussed on analysis and experimentation\\nDeliver insight, analysis using statistical tools, data visualization, and business use case to product and business teamPerform analysis in relation to determining new project pilot settings, new features, user behavior, and in-app behavior\\nBuild maintain dashboards for tracking business performance and product adoption Partner with Lead or Senior Analyst to help Product Managers and Business teams create decision-based on decision science\\nPartner with Lead or Senior Analyst in identifying product or business opportunities and support in product delivery such as experimentation\\nBuild first cut Machine Learning models based on product requirementsCreate and automate data extraction by creating denormalized tables\\nWhat You Will Need\\n2+ years of experience with basic statistics or product analytics along with strong business acumen\\nExpert in SQL and strong experience with a data visualization and dashboarding tool (e.g. Tableau, Metabase, Google Data Studio, Clevertap, Python, etc)\\nExposure in working with Machine Learning (forecasting, clustering, statistical significance test, predictive modeling, and text mining) is a plus\\nExperience in helping Product Team or Business team to deliver products as end-to-end data solutions (from data pipelining to analysis, presenting, and scalable adaption)\\nComfortable working with minimal guidance and in a team setting\\nAbility to use critical thinking daily to manage daily tasks while being goal-orientedAbility to transform an ambiguous business or product problem into a well-scoped and impactful analysis; able to design simple experiments .',\n",
       " 'Key Responsibilities:\\nProject Execution:\\nBuild and exhibit deep expertise on available marketing data sets and supports data enabled decision making using data from different Lilly affiliates\\nApply knowledge of digital activities to integrate data into customer journeys\\nPerform root cause analysis in collaboration with end-users, related to reports, dashboards, visualizations\\nConsistent delivery of high quality, timely and insightful reports to enable brand and senior leadership to track performance of Eli Lilly brands\\nDevelop and publish regularly, marketing reports on KPIs related to P2P and Video On Demand and non-personal channel promotional impressions and engagement metrics etc.\\nWork on descriptive analytical models, to perform exploratory data analysis and answer unstructured questions from the business.\\nConversion funnel analytics\\nSales Rep Compliance analytics\\nBrand marketing analytics\\nConversion funnel analytics\\nSales Rep Compliance analytics\\nBrand marketing analytics\\nSupport various phases of the project including kick-off, methodology development, execution, insight generation and data visualization and results presentation to various stakeholders\\nFind and execute opportunities for productivity improvements by automation or process changes\\nRequirements\\nPreferred degree in sciences or quantitative discipline i.e. Econometrics, Statistics, Engineering or Computer Sciences\\nAt least 5 years of evolving experience in business analytics, performance reporting and/or descriptive analytics for Marketing or other commercial leadership, with demonstrated results in understanding, structuring and making sense of unfamiliar and messy datasets\\nExperience in working with business partners located in another country\\nInterpersonal and communication skills, with ability to work, remotely, across time zones\\nAbility to operate effectively in an international matrix environment\\nPreferred Technical Skills\\nHands-on experience of managing and querying data on a range of relational and decisional data servers\\nExpertise in writing and debugging efficient SQL queries, Excel and VBA\\nKnime & Tableau experience highly desirable\\nExperience in business analytics tasks like data cleaning, data enrichment, preparation and basics of good reporting\\nHigh learning agility and focus on integration',\n",
       " '  Analyst Profile - Secondary Researcher and analysis\\n\\nProven secondary research and Analysis experience\\nAbility to interpret large amounts of data and to multi-task\\nStrong communication and presentation skills\\nSearch engines, web analytics, and business research tools acumen\\nAdequate knowledge of data collection methods (polls, focus groups, surveys etc.)\\nStrong analytical and critical thinking',\n",
       " \"Job Description\\n\\nJob Title: Principal Analyst\\n\\nPURPOSE OF ROLE\\n\\nPerform complex reporting of data processes for High Level Sales/Shares/Volume/Trend to Key Stakeholders\\nOwn specific processes and will be responsible for accurate reporting and any inquiries from customers, employees & management\\nDevelops, analyzes and provides business & sales insights, sales to evaluate performance and business health\\nPrepared Power BI Dashboards on top of Excel or other Data Warehouses like SQL.\\n\\nKEY TASKS AND ACCOUNTABILITIES\\n\\nPerforms data extraction, process & reporting analysis, own the process & reports and act as a point of contact for any queries which come from stakeholders & management\\nDevelops and produces new reports, analyzes current processes and procedures to determine alternative solutions to streamline and create more effective/efficient solutions\\nManipulates data and draws meaningful insights from large datasets using statistical computer languages (SAS, SQL & Python)\\nDevelop Power BI dashboards using excel, SharePoint, SQL DW as source, write DAX queries for complex dashboard setups\\nPerforms routine reports including data validation and report analysis with a high level of accuracy and timeliness\\nProvides stakeholders with the necessary support, reports, tools, and data analysis\\nConduct analysis of weekly, monthly, quarterly, and annual reports or processes\\nDeliver Adhoc reports as per stakeholder requirements, within specific deadlines whilst ensuring routine reports are on track\\nAble to prioritize workload and work in pressured environment\\nDelivery of activities to support Service Level Agreements\\nMaintain standards and controls to deliver error free reporting\\n\\n\\n\\nGeographical Scope: NAZ (US & CAN), Europe\\n\\n. QUALIFICATIONS, EXPERIENCE, SKILLS\\n\\nPlease list the following requirements\\nLevel of educational attainment required:\\nMasters in Business Administration / Masters Degree in IT / Computer science\\n\\nProfessional qualifications and accreditations/memberships required:\\nPreferred SAS, SQL & Python certification / Any kind of data analytics, Power BI\\n\\nPrevious work experience required\\n4 to 9+ years experience providing analytical support to a business unit or similar experience analyzing data in consumer goods\\nLanguage skills required\\nGood verbal & written communication skills\\nAbility to articulate the data interpretation & Insights\\nStory boarding and structure in data analysis\\n\\nIT skills required\\nExperience of SAS 9.3/9.4, SAS Macros, Proc SQL and SAS Connectors (with Snowflake, Teradata, SharePoint, etc.)\\nIntermediate/Advanced Power BI expertise\\nWorking knowledge of SQL syntax, performing various data pulls and data wrangling using SQL scripts. Developing SQL Scripts to provide final data extracts to the Power BI and VBA dashboards.\\nExperience of Data Management using Python libraries like Numpy, Pandas and Scipy.\\nKnowledge of Snowflake cloud platform (Preferred)\\nKnowledge with MS Office Suite including proficiency with Excel. Strong Excel modeling skills essential including using VBA\\nAnalytical and problem solving skills\\n\\n\\n\\n\\n\\nCOMPETENCIES\\n\\nPlease list the technical competencies for optimal performance. Differentiate between essential, desirable, and less relevant technical competencies.\\n\\nBehavioural Competencies:\\n\\nAbility to work in dynamic team environment\\nHigh level ownership and commitment levels\\nShould have strong co-ordination and cross functional skills\\n\\nInterpersonal Expertise:\\nGood verbal & written communication skills\\nStrong in stakeholder management\\n\\n\\n\\n\\nAB InBev Principal Analyst, CP&A NAZ\\n\\nWe're looking for a motivated, analytical-minded candidate who wants to be part of a start-up style environment that combines the resources and future mobility offered by a large corporation. Ideally, you have the base skill set for the role and are willing to take on (or teach yourself to take on) any challenge. You may go from creating process documents & SOPs, to preparing strategic reports, to develop programing based dashboards, to providing analysis and insights on sales data, to presenting to company Directors/Vice Presidents all in the same week.\\n\\nEducation:\\n* Bachelors or Masters (preferred)\\n\\nMandatory Requirements:\\n* Strong written and verbal English skills\\n* Proficient analytic and market research skills\\n* Strong skills in assessing the data quality of reports\\n* Microsoft Office skills (Excel (critical), PowerPoint, Word)\\n* Project Management Skills\\n* Strong programing skills (preferably SAS, SQL, Python, VBA, Power BI)\\n\\n\\n\\nPrimary Responsibilities:\\n\\nPerform data extraction, develop presentations / reviews, deriving analysis on underlying data and providing meaningful insights for US and Canada Beer Market\\nDevelop the backend ETL programs for Power BI/Excel dashboards using SAS, SQL and Python\\nOwn the process and reports and act as a point of contact for any queries which comes from internal customers & top management\\nDevelops and produces new reports, analyzes current processes or procedures within the scope of work to determine alternative solutions to streamline and create more effective/efficient solutions.\\nPerforms routine reports including data validation and report analysis with a high level of accuracy and timeliness\\nProvides customers with the necessary support, reports, tools, and data analysis\\nHandle change management for existing scope of work\\nDeliver Adhoc reports as per customer requirement, within specific deadlines whilst ensuring routine reports are on track\\nAble to prioritize workload and work in pressured environment\\nWork within the prescribed guidelines to comply with Service Level Agreements\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_desc=[]\n",
    "for i in job_url:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        job_=driver.find_element_by_xpath('//section[@class=\"job-desc\"]//div')\n",
    "        job_desc.append(job_.text)\n",
    "    except:\n",
    "        pass\n",
    "job_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# slicing the list to only contain 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_desc=job_desc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataframe with the help of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naukri_2=pd.DataFrame({\"Company Name\":company_name,\"Location\":location,\"Designation\":job_profile,\"Job Description\":job_desc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Senior Specialist - Data Analyst</td>\n",
       "      <td>Managing and ensuring data quality, integrit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGI Information Systems and Management Consult...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Business/Data Analyst - SSE/LA</td>\n",
       "      <td>Company systems organization structure, system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Infobahn Softworld Inc.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Business Data Analyst II</td>\n",
       "      <td>Dear Candidates\\n\\nWe have a Immediate require...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WEIWO Communication Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru(Ulsoor)</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Position Title: Service Data &amp; Contract Analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Job Overview\\nWe are looking for a hands-on, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>We are looking for data analyst with experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>India Medtronic Pvt. Ltd,.</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>Data Analyst/Business Analyst-Gurgaon/Bangalor...</td>\n",
       "      <td>1. Azure Analytics (Preferred)\\n2. SQL (Prefer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMEDC SERVICES PRIVATE LIMITED</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>The responsibilities of the Data Engineer (Tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Works independently under limited supervision ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Role : Senior Data Analyst\\n\\nRequired Skills ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name  \\\n",
       "0                              Philips India Limited   \n",
       "1  CGI Information Systems and Management Consult...   \n",
       "2                            Infobahn Softworld Inc.   \n",
       "3                      WEIWO Communication Pvt. Ltd.   \n",
       "4                                   Trigent Software   \n",
       "5                                   Trigent Software   \n",
       "6                         India Medtronic Pvt. Ltd,.   \n",
       "7                     SMEDC SERVICES PRIVATE LIMITED   \n",
       "8                   Allegis Services India Pvt. Ltd.   \n",
       "9                   Allegis Services India Pvt. Ltd.   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                        Bangalore/Bengaluru(Ulsoor)   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                 (WFH during Covid)   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                         Designation  \\\n",
       "0                   Senior Specialist - Data Analyst   \n",
       "1                     Business/Data Analyst - SSE/LA   \n",
       "2                           Business Data Analyst II   \n",
       "3                                       Data Analyst   \n",
       "4                              Business Data Analyst   \n",
       "5                              Business Data Analyst   \n",
       "6  Data Analyst/Business Analyst-Gurgaon/Bangalor...   \n",
       "7                                Senior Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                     Job Description  \n",
       "0    Managing and ensuring data quality, integrit...  \n",
       "1  Company systems organization structure, system...  \n",
       "2  Dear Candidates\\n\\nWe have a Immediate require...  \n",
       "3  Position Title: Service Data & Contract Analys...  \n",
       "4  Job Overview\\nWe are looking for a hands-on, d...  \n",
       "5  We are looking for data analyst with experienc...  \n",
       "6  1. Azure Analytics (Preferred)\\n2. SQL (Prefer...  \n",
       "7  The responsibilities of the Data Engineer (Tec...  \n",
       "8  Works independently under limited supervision ...  \n",
       "9  Role : Senior Data Analyst\\n\\nRequired Skills ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_naukri_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the webdriver and entering the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating to the search bar and entering the keys as Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_des=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'input[id=\"qsb-keyword-sugg\"]')))\n",
    "skill_des.clear()\n",
    "skill_des.send_keys(\"Data Scientist\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clicking the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'button[class=\"btn\"]'))).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element_by_xpath('//label[@for=\"chk-Delhi / NCR-cityTypeGid-\"]/i[@class=\"fleft naukicon naukicon-checkbox\"]').is_selected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying various filters for our job search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('//label[@for=\"chk-Delhi / NCR-cityTypeGid-\"]/i[@class=\"fleft naukicon naukicon-checkbox\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element_by_xpath('//label[@for=\"chk-3-6 Lakhs-ctcFilter-\"]/i[@class=\"fleft naukicon naukicon-checkbox\"]').is_selected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('//label[@for=\"chk-3-6 Lakhs-ctcFilter-\"]/i[@class=\"fleft naukicon naukicon-checkbox\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the empty lists for our final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "exp_req=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting all job_titles from website and gathering data into our empty list job_title with the help of for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_t=driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in job_t:\n",
    "    x=i.text\n",
    "    job_title.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting all job_locations from website and gathering data into our empty list job_location with the help of for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_l=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in job_l:\n",
    "    x=i.text\n",
    "    job_location.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting all company_names from website and gathering data into our empty list company_name with the help of for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_n=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in comp_n:\n",
    "    x=i.text\n",
    "    company_name.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting all experience_required from website and gathering data into our empty list exp_req with the help of for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in exp:\n",
    "    x=i.text\n",
    "    exp_req.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing all the lists to only contain 10 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=job_title[0:10]\n",
    "job_location=job_location[0:10]\n",
    "company_name=company_name[0:10]\n",
    "exp_req=exp_req[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataframe with the help of our list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naukri_3=pd.DataFrame({\"Job Title\":job_title,\"Job Location\":job_location,\"Comapny Name\":company_name,\"Experience Required\":exp_req})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Comapny Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist / Sr. Data Scientist</td>\n",
       "      <td>Noida, Pune, Mumbai (All Areas)</td>\n",
       "      <td>WEGARNER SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>CARS24</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Immediate Openings For DATA Scientist with 6 T...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Entune IT Consulting Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Decimal Technologies Pvt Ltd.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist - Noida</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring Data Scientist Develope || IDS Infotech...</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>IDS Infotech Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring Data Scientist Develope || IDS Infotech...</td>\n",
       "      <td>Chandigarh, Hyderabad/Secunderabad, Chennai, B...</td>\n",
       "      <td>IDS Infotech Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                     Data Scientist   \n",
       "1                Data Scientist / Sr. Data Scientist   \n",
       "2  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "3                      Data Scientist / Data Analyst   \n",
       "4  Immediate Openings For DATA Scientist with 6 T...   \n",
       "5                                     Data Scientist   \n",
       "6                      Senior Data Scientist - Noida   \n",
       "7                                     Data Scientist   \n",
       "8  Hiring Data Scientist Develope || IDS Infotech...   \n",
       "9  Hiring Data Scientist Develope || IDS Infotech...   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                   Gurgaon/Gurugram   \n",
       "1                    Noida, Pune, Mumbai (All Areas)   \n",
       "2               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "5                                 (WFH during Covid)   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7                                              Noida   \n",
       "8                             Noida(Sector-59 Noida)   \n",
       "9  Chandigarh, Hyderabad/Secunderabad, Chennai, B...   \n",
       "\n",
       "                                     Comapny Name Experience Required  \n",
       "0                         CBRE South Asia Pvt Ltd             2-4 Yrs  \n",
       "1              WEGARNER SOLUTIONS PRIVATE LIMITED             0-5 Yrs  \n",
       "2                       GABA Consultancy services             0-0 Yrs  \n",
       "3                                          CARS24             1-5 Yrs  \n",
       "4            Entune IT Consulting Private Limited             5-8 Yrs  \n",
       "5                   Decimal Technologies Pvt Ltd.             1-3 Yrs  \n",
       "6  Optum Global Solutions (India) Private Limited             2-6 Yrs  \n",
       "7                    R Systems International Ltd.            5-10 Yrs  \n",
       "8                               IDS Infotech Ltd.            5-10 Yrs  \n",
       "9                               IDS Infotech Ltd.            5-10 Yrs  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_naukri_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the webdriver and feeding the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clicking to the sign in button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "signin=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'button[class=\"d-flex align-items-center justify-content-center order-1 order-md-2 mr-auto mr-md-0 p-0 LockedHomeHeaderStyles__signInButton\"'))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entering emailid and password and clicking the signin button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_signin=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'input[id=\"userEmail\"]')))\n",
    "password=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'input[id=\"userPassword\"]')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_signin.clear()\n",
    "password.clear()\n",
    "email_signin.send_keys(\"pranavpandeyd1@gmail.com\")\n",
    "password.send_keys(\"seleniumglassdoor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "signin=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.XPATH,'//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]'))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entering the values of job_title and job_location and later pressing the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'input[id=\"sc.keyword\"]')))\n",
    "location=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'input[id=\"sc.location\"]')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title.clear()\n",
    "location.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title.send_keys(\"Data Scientist\")\n",
    "location.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchjobs=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'button[class=\"gd-ui-button ml-std col-auto search__SearchStyles__newSearchButton css-1dqvyh7\"]'))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name=[]\n",
    "num_day=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using for loops to add the extracted data into our empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp=driver.find_elements_by_xpath('//a[@class=\" css-l2wjgv e1n63ojh0 jobLink\"]/span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in comp:\n",
    "    x=i.text\n",
    "    company_name.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=driver.find_elements_by_xpath('//div[@class=\"d-flex align-items-end pl-std css-mi55ob\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in number:\n",
    "    x=i.text\n",
    "    num_day.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat=driver.find_elements_by_xpath('//div//span[@class=\"css-19pjha7 e1cjmv6j1\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in rat:\n",
    "    x=i.text\n",
    "    rating.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing the lists to only contain 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name=company_name[0:10]\n",
    "num_day=num_day[0:10]\n",
    "rating=rating[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataframe from our lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glass=pd.DataFrame({\"Company Name\":company_name,\"Number of days ago job posted\":num_day,\"Ratings\":rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Number of days ago job posted</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>9d</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pixel Vision</td>\n",
       "      <td>19d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Newgen Software</td>\n",
       "      <td>20d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crowe</td>\n",
       "      <td>30d+</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>4d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>2d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Innovacer</td>\n",
       "      <td>1d</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company Name Number of days ago job posted Ratings\n",
       "0  Liberin Technologies Private Limited                            9d     3.3\n",
       "1                          Pixel Vision                           19d     3.8\n",
       "2                       Newgen Software                           20d     4.1\n",
       "3                                 Crowe                          30d+     5.0\n",
       "4          Salasar New Age Technologies                          30d+     3.9\n",
       "5                              Ericsson                            4d     4.1\n",
       "6                              Techlive                          30d+     3.8\n",
       "7                         NatWest Group                            2d     3.7\n",
       "8                        Biz2Credit Inc                          30d+     3.8\n",
       "9                             Innovacer                            1d     3.1"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_glass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the Webdriver and entering the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clicking on the sign in button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "signin=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'button[class=\"d-flex align-items-center justify-content-center order-1 order-md-2 mr-auto mr-md-0 p-0 LockedHomeHeaderStyles__signInButton\"]')))\n",
    "time.sleep(10)\n",
    "signin.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_signin=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'input[id=\"userEmail\"]')))\n",
    "password=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'input[id=\"userPassword\"]')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entering the Sign in credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_signin.clear()\n",
    "password.clear()\n",
    "email_signin.send_keys(\"pranavpandeyd1@gmail.com\")\n",
    "password.send_keys(\"seleniumglassdoor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clicking the login button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "signin=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.XPATH,'//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]'))).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title= WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.XPATH,'//input[@id=\"sc.keyword\"]')))\n",
    "location= WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.XPATH,'//input[@id=\"sc.location\"]')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title.clear()\n",
    "location.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing keys for the job title and  job location thereafter clicking search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title.send_keys(\"Data Scientist\")\n",
    "location.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchjobs=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'button[class=\"gd-ui-button ml-std col-auto search__SearchStyles__newSearchButton css-1dqvyh7\"]'))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering the data from the glassdoor website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_detail=[]\n",
    "companies=driver.find_elements_by_xpath('//div[@class=\"d-flex flex-column pl-sm css-1d3xmk8 e1rrn5ka4\"]')\n",
    "\n",
    "for i in companies:\n",
    "\n",
    "    if i.text is None :\n",
    "\n",
    "        company_detail.append(\"--\") \n",
    "\n",
    "    else:\n",
    "\n",
    "        company_detail.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liberin Technologies Private Limited\\nAssociate Data Scientist\\nNoida\\n₹3L - ₹7L (Employer Est.)\\nEasy Apply\\n16d',\n",
       " 'Data Trained Education\\nData Science Intern\\nNoida\\n₹1L - ₹3L (Employer Est.)\\nEasy Apply\\n6d',\n",
       " 'Pixel Vision\\nData Scientist Intern\\nNoida\\nEasy Apply\\n26d',\n",
       " 'Emerging India Analytics\\nData Science Training Head-Full Time\\nNoida\\n₹4L - ₹6L (Employer Est.)\\nEasy Apply\\n7d',\n",
       " 'CRMNEXT\\nData Scientist Team Leader\\nNoida\\nNew\\n1d',\n",
       " 'Crowe\\nData Scientist\\nNoida\\n30d+',\n",
       " 'Techlive\\nData Scientist\\nNoida\\n30d+',\n",
       " 'Biz2Credit Inc\\nData Scientist\\nNoida\\nEasy Apply\\n30d+',\n",
       " 'Ericsson\\nData Scientist\\nNoida\\n11d',\n",
       " 'Newgen Software\\nData Scientist\\nNoida\\n27d',\n",
       " 'Salasar New Age Technologies\\nData Scientist Intern\\nNoida\\n30d+',\n",
       " 'Uncodemy\\nData Science with AI,ML,DEEP Learning Trainer\\nNoida\\n₹4L - ₹7L (Employer Est.)\\nEasy Apply\\n7d',\n",
       " 'DataTrained\\nData Science Internship\\nNoida\\n₹60T - ₹1L (Employer Est.)\\n5d',\n",
       " 'Aliqan Technologies\\nData Scientist\\nGurgaon\\n₹27L - ₹32L (Employer Est.)\\nEasy Apply\\n29d',\n",
       " 'British Council\\nBusiness Analyst - Data Science & Analytics\\nNoida\\n5d',\n",
       " 'NatWest Group\\nManager - Data Scientist\\nGurgaon\\nNew\\n2d',\n",
       " 'UnitedHealth Group\\nData Scientist - Noida, UP\\nNoida\\n30d+',\n",
       " 'SearchUrCollege\\nData Scientist\\nNoida\\n30d+',\n",
       " 'NEC Opportunities\\nData Scientist\\nNew Delhi\\n8d',\n",
       " 'Conduent\\nData Scientist IV\\nNoida\\nEasy Apply\\n30d+',\n",
       " 'Deciman\\nData Scientist\\nGurgaon\\n15d',\n",
       " 'Innovacer\\nSenior Data Scientist(NLP)\\nNoida\\n30d+',\n",
       " 'Innovacer\\nLead Data Scientist\\nNoida\\n8d',\n",
       " 'Amantya Technologies\\nData Scientist\\nGurgaon\\nNew\\n3d',\n",
       " 'Salasar New Age Technologies\\nData Scientist\\nNoida\\n30d+',\n",
       " 'WishFin\\nData Scientist\\nNoida\\n30d+',\n",
       " 'Innobuzz\\nData Science Trainer\\nNew Delhi\\n₹4L - ₹6L (Employer Est.)\\nNew\\nEasy Apply\\n2d',\n",
       " 'McKinsey & Company\\nData Scientist - QuantumBlack\\nGurgaon\\n5d',\n",
       " 'Emerging India Group\\nAssistant Manager/Deputy Manager/Manager - Sales - Data Analytics Training Solutions\\nNoida\\n₹5L (Employer Est.)\\n30d+',\n",
       " 'Decision Tree Analytics And Services\\nData Analytics Internship\\nGurgaon\\n₹2L (Employer Est.)\\n6d']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have got the all details in this list, we will manipulate the list to extract every single feature from it.\n",
    "company_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Trained Education',\n",
       " 'Data Science Intern',\n",
       " 'Noida',\n",
       " '₹1L - ₹3L (Employer Est.)',\n",
       " 'Easy Apply',\n",
       " '6d']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_detail[1].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using for loops to add the data in empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are taking only those companies which has maximum and minum salary mentioned\n",
    "companies=[]\n",
    "for i in company_name:\n",
    "    if u\"\\u20B9\" in i:\n",
    "        companies.append(i)\n",
    "    else:\n",
    "        companies.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liberin Technologies Private Limited\\nAssociate Data Scientist\\nNoida\\n₹3L - ₹7L (Employer Est.)\\nEasy Apply\\n16d',\n",
       " 'Data Trained Education\\nData Science Intern\\nNoida\\n₹1L - ₹3L (Employer Est.)\\nEasy Apply\\n6d',\n",
       " '-',\n",
       " 'Emerging India Analytics\\nData Science Training Head-Full Time\\nNoida\\n₹4L - ₹6L (Employer Est.)\\nEasy Apply\\n7d',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " 'Uncodemy\\nData Science with AI,ML,DEEP Learning Trainer\\nNoida\\n₹4L - ₹7L (Employer Est.)\\nEasy Apply\\n7d',\n",
       " 'DataTrained\\nData Science Internship\\nNoida\\n₹60T - ₹1L (Employer Est.)\\n5d',\n",
       " 'Aliqan Technologies\\nData Scientist\\nGurgaon\\n₹27L - ₹32L (Employer Est.)\\nEasy Apply\\n29d',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " 'Innobuzz\\nData Science Trainer\\nNew Delhi\\n₹4L - ₹6L (Employer Est.)\\nNew\\nEasy Apply\\n2d',\n",
       " '-',\n",
       " 'Emerging India Group\\nAssistant Manager/Deputy Manager/Manager - Sales - Data Analytics Training Solutions\\nNoida\\n₹5L (Employer Est.)\\n30d+',\n",
       " 'Decision Tree Analytics And Services\\nData Analytics Internship\\nGurgaon\\n₹2L (Employer Est.)\\n6d']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "company_rup=[]\n",
    "\n",
    "for i in tony:\n",
    "    i.split(\"\\n\")\n",
    "    if u\"\\u20B9\" in i:\n",
    "        company_rup.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liberin Technologies Private Limited\\nAssociate Data Scientist\\nNoida\\n₹3L - ₹7L (Employer Est.)\\nEasy Apply\\n16d',\n",
       " 'Data Trained Education\\nData Science Intern\\nNoida\\n₹1L - ₹3L (Employer Est.)\\nEasy Apply\\n6d',\n",
       " 'Emerging India Analytics\\nData Science Training Head-Full Time\\nNoida\\n₹4L - ₹6L (Employer Est.)\\nEasy Apply\\n7d',\n",
       " 'Uncodemy\\nData Science with AI,ML,DEEP Learning Trainer\\nNoida\\n₹4L - ₹7L (Employer Est.)\\nEasy Apply\\n7d',\n",
       " 'DataTrained\\nData Science Internship\\nNoida\\n₹60T - ₹1L (Employer Est.)\\n5d',\n",
       " 'Aliqan Technologies\\nData Scientist\\nGurgaon\\n₹27L - ₹32L (Employer Est.)\\nEasy Apply\\n29d',\n",
       " 'Innobuzz\\nData Science Trainer\\nNew Delhi\\n₹4L - ₹6L (Employer Est.)\\nNew\\nEasy Apply\\n2d',\n",
       " 'Emerging India Group\\nAssistant Manager/Deputy Manager/Manager - Sales - Data Analytics Training Solutions\\nNoida\\n₹5L (Employer Est.)\\n30d+',\n",
       " 'Decision Tree Analytics And Services\\nData Analytics Internship\\nGurgaon\\n₹2L (Employer Est.)\\n6d']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_rup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "for i in india:\n",
    "    name.append(i.split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max=[]\n",
    "for i in india:\n",
    "    min_max.append(i.split(\"\\n\")[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹3L - ₹7L (Employer Est.)',\n",
       " '₹1L - ₹3L (Employer Est.)',\n",
       " '₹4L - ₹6L (Employer Est.)',\n",
       " '₹4L - ₹7L (Employer Est.)',\n",
       " '₹60T - ₹1L (Employer Est.)',\n",
       " '₹27L - ₹32L (Employer Est.)',\n",
       " '₹4L - ₹6L (Employer Est.)',\n",
       " '₹5L (Employer Est.)',\n",
       " '₹2L (Employer Est.)']"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_profile=[]\n",
    "for i in india:\n",
    "    job_profile.append(i.split(\"\\n\")[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Associate Data Scientist',\n",
       " 'Data Science Intern',\n",
       " 'Data Science Training Head-Full Time',\n",
       " 'Data Science with AI,ML,DEEP Learning Trainer',\n",
       " 'Data Science Internship',\n",
       " 'Data Scientist',\n",
       " 'Data Science Trainer',\n",
       " 'Assistant Manager/Deputy Manager/Manager - Sales - Data Analytics Training Solutions',\n",
       " 'Data Analytics Internship']"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glassdoor=pd.DataFrame({\"Company Name\":name,\"Salary Range\":min_max,\"Job Designation\":job_profile})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Salary Range</th>\n",
       "      <th>Job Designation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>₹3L - ₹7L (Employer Est.)</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Trained Education</td>\n",
       "      <td>₹1L - ₹3L (Employer Est.)</td>\n",
       "      <td>Data Science Intern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emerging India Analytics</td>\n",
       "      <td>₹4L - ₹6L (Employer Est.)</td>\n",
       "      <td>Data Science Training Head-Full Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uncodemy</td>\n",
       "      <td>₹4L - ₹7L (Employer Est.)</td>\n",
       "      <td>Data Science with AI,ML,DEEP Learning Trainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DataTrained</td>\n",
       "      <td>₹60T - ₹1L (Employer Est.)</td>\n",
       "      <td>Data Science Internship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aliqan Technologies</td>\n",
       "      <td>₹27L - ₹32L (Employer Est.)</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Innobuzz</td>\n",
       "      <td>₹4L - ₹6L (Employer Est.)</td>\n",
       "      <td>Data Science Trainer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Emerging India Group</td>\n",
       "      <td>₹5L (Employer Est.)</td>\n",
       "      <td>Assistant Manager/Deputy Manager/Manager - Sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree Analytics And Services</td>\n",
       "      <td>₹2L (Employer Est.)</td>\n",
       "      <td>Data Analytics Internship</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company Name                 Salary Range  \\\n",
       "0  Liberin Technologies Private Limited    ₹3L - ₹7L (Employer Est.)   \n",
       "1                Data Trained Education    ₹1L - ₹3L (Employer Est.)   \n",
       "2              Emerging India Analytics    ₹4L - ₹6L (Employer Est.)   \n",
       "3                              Uncodemy    ₹4L - ₹7L (Employer Est.)   \n",
       "4                           DataTrained   ₹60T - ₹1L (Employer Est.)   \n",
       "5                   Aliqan Technologies  ₹27L - ₹32L (Employer Est.)   \n",
       "6                              Innobuzz    ₹4L - ₹6L (Employer Est.)   \n",
       "7                  Emerging India Group          ₹5L (Employer Est.)   \n",
       "8  Decision Tree Analytics And Services          ₹2L (Employer Est.)   \n",
       "\n",
       "                                     Job Designation  \n",
       "0                           Associate Data Scientist  \n",
       "1                                Data Science Intern  \n",
       "2               Data Science Training Head-Full Time  \n",
       "3      Data Science with AI,ML,DEEP Learning Trainer  \n",
       "4                            Data Science Internship  \n",
       "5                                     Data Scientist  \n",
       "6                               Data Science Trainer  \n",
       "7  Assistant Manager/Deputy Manager/Manager - Sal...  \n",
       "8                          Data Analytics Internship  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_glassdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the chrome webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.flipkart.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross=driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_des=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating to search bar entering key of sunglasses and then clicking the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar.send_keys(\"Sunglasses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clicking the search button after inserting the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_click=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using for loops to extract the data from the links to the empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[\"https://www.flipkart.com/search?q=Sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=1\",\"https://www.flipkart.com/search?q=Sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=2\",\"https://www.flipkart.com/search?q=Sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=3\",\"https://www.flipkart.com/search?q=Sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[0])\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "for i in range(0,40):\n",
    "    brand.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[1])\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "for i in range(0,40):\n",
    "    brand.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[2])\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "for i in range(0,40):\n",
    "    brand.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[0])\n",
    "x=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "for i in range(0,38):\n",
    "    product_des.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[1])\n",
    "x=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "for i in range(0,38):\n",
    "    product_des.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[2])\n",
    "x=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "for i in range(0,38):\n",
    "    product_des.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[0])\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "\n",
    "for i in range(0,38):\n",
    "    price.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[1])\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "\n",
    "for i in range(0,38):\n",
    "    price.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[2])\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "\n",
    "for i in range(0,38):\n",
    "    price.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[0])\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]/span')\n",
    "\n",
    "for i in range(0,38):\n",
    "    discount.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[1])\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]/span')\n",
    "\n",
    "for i in range(0,38):\n",
    "    discount.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[2])\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]/span')\n",
    "\n",
    "for i in range(0,38):\n",
    "    discount.append(x[i].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing the lists to only contain 100 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=brand[0:100]\n",
    "product_des=product_des[0:100]\n",
    "discount=discount[0:100]\n",
    "price=price[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataframe with the help of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sunglasses=pd.DataFrame({\"Brand\":brand,\"Price\":price,\"Discount Offer\":discount,\"Product Description\":product_des})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount Offer</th>\n",
       "      <th>Product Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wrogn</td>\n",
       "      <td>₹663</td>\n",
       "      <td>73% off</td>\n",
       "      <td>Mirrored Wayfarer Sunglasses (51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹899</td>\n",
       "      <td>55% off</td>\n",
       "      <td>Polarized Retro Square Sunglasses (58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88% off</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹513</td>\n",
       "      <td>35% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fravy</td>\n",
       "      <td>₹549</td>\n",
       "      <td>57% off</td>\n",
       "      <td>Others Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹499</td>\n",
       "      <td>66% off</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹314</td>\n",
       "      <td>84% off</td>\n",
       "      <td>UV Protection, Gradient Wayfarer Sunglasses (53)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹399</td>\n",
       "      <td>81% off</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹664</td>\n",
       "      <td>45% off</td>\n",
       "      <td>Others Retro Square Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Price Discount Offer  \\\n",
       "0       Wrogn  ₹663        73% off   \n",
       "1   ROYAL SON  ₹899        55% off   \n",
       "2    Fastrack  ₹758        15% off   \n",
       "3   Elligator  ₹295        88% off   \n",
       "4    Fastrack  ₹513        35% off   \n",
       "..        ...   ...            ...   \n",
       "95      Fravy  ₹549        57% off   \n",
       "96  ROYAL SON  ₹499        66% off   \n",
       "97   Fastrack  ₹314        84% off   \n",
       "98   Fastrack  ₹399        81% off   \n",
       "99  ROYAL SON  ₹664        45% off   \n",
       "\n",
       "                                  Product Description  \n",
       "0                   Mirrored Wayfarer Sunglasses (51)  \n",
       "1              Polarized Retro Square Sunglasses (58)  \n",
       "2       UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "3                 UV Protection Round Sunglasses (54)  \n",
       "4    UV Protection Rectangular Sunglasses (Free Size)  \n",
       "..                                                ...  \n",
       "95             Others Wayfarer Sunglasses (Free Size)  \n",
       "96         UV Protection Retro Square Sunglasses (58)  \n",
       "97   UV Protection, Gradient Wayfarer Sunglasses (53)  \n",
       "98  UV Protection Retro Square Sunglasses (Free Size)  \n",
       "99         Others Retro Square Sunglasses (Free Size)  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating few empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=[]\n",
    "fullre=[]\n",
    "review_sum=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "link=[\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]    #for the rating data\n",
    "af=[]   #for the full review data\n",
    "ar=[]   #for the review summary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using for loop to put the data in our empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first \n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(1))\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in x:\n",
    "    a.append(i.text)\n",
    "\n",
    "\n",
    "y=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "for i in y:\n",
    "    af.append(i.text)\n",
    "\n",
    "\n",
    "z=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "for i in z:\n",
    "    ar.append(i.text)\n",
    "#second    \n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(2))\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in x:\n",
    "    a.append(i.text)\n",
    "\n",
    "\n",
    "y=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "for i in y:\n",
    "    af.append(i.text)\n",
    "\n",
    "\n",
    "z=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "for i in z:\n",
    "    ar.append(i.text)\n",
    "    \n",
    " #third   \n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(3))\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in x:\n",
    "    a.append(i.text)\n",
    "\n",
    "\n",
    "y=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "for i in y:\n",
    "    af.append(i.text)\n",
    "\n",
    "\n",
    "z=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "for i in z:\n",
    "    ar.append(i.text)\n",
    " #fourth   \n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(4))\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in x:\n",
    "    a.append(i.text)\n",
    "\n",
    "\n",
    "y=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "for i in y:\n",
    "    af.append(i.text)\n",
    "\n",
    "\n",
    "z=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "for i in z:\n",
    "    ar.append(i.text)\n",
    "#fifth    \n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(5))\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in x:\n",
    "    a.append(i.text)\n",
    "\n",
    "\n",
    "y=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "for i in y:\n",
    "    af.append(i.text)\n",
    "\n",
    "\n",
    "z=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "for i in z:\n",
    "    ar.append(i.text)\n",
    " #sixth   \n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(6))\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in x:\n",
    "    a.append(i.text)\n",
    "\n",
    "\n",
    "y=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "for i in y:\n",
    "    af.append(i.text)\n",
    "\n",
    "\n",
    "z=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "for i in z:\n",
    "    ar.append(i.text)\n",
    " #seventh   \n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(7))\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in x:\n",
    "    a.append(i.text)\n",
    "\n",
    "\n",
    "y=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "for i in y:\n",
    "    af.append(i.text)\n",
    "\n",
    "\n",
    "z=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "for i in z:\n",
    "    ar.append(i.text)\n",
    " #eigth   \n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(8))\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in x:\n",
    "    a.append(i.text)\n",
    "\n",
    "\n",
    "y=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "for i in y:\n",
    "    af.append(i.text)\n",
    "\n",
    "\n",
    "z=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "for i in z:\n",
    "    ar.append(i.text)\n",
    " #nineth   \n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(9))\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in x:\n",
    "    a.append(i.text)\n",
    "\n",
    "\n",
    "y=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "for i in y:\n",
    "    af.append(i.text)\n",
    "\n",
    "\n",
    "z=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "for i in z:\n",
    "    ar.append(i.text)\n",
    " #tenth   \n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(10))\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in x:\n",
    "    a.append(i.text)\n",
    "\n",
    "\n",
    "y=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "for i in y:\n",
    "    af.append(i.text)\n",
    "\n",
    "\n",
    "z=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "for i in z:\n",
    "    ar.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "af=af[0:98]\n",
    "ar=ar[0:98]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iphone=pd.DataFrame({\"Ratings\":a,\"Summary Review\":ar,\"Full Review\":af})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Summary Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Everything is perfect pictures come out so cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>The ultimate performance\\nCamera is superb\\nTh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings     Summary Review  \\\n",
       "0        5          Brilliant   \n",
       "1        5     Simply awesome   \n",
       "2        5   Perfect product!   \n",
       "3        5          Fabulous!   \n",
       "4        5  Worth every penny   \n",
       "..     ...                ...   \n",
       "93       5            Awesome   \n",
       "94       5     Decent product   \n",
       "95       5             Super!   \n",
       "96       5          Fabulous!   \n",
       "97       5          Just wow!   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   This is my first iOS phone. I am very happy wi...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "93  The phone is completely good\\nAs far as camera...  \n",
       "94  Everything u ll like it when u use this iPhone...  \n",
       "95  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "96  Everything is perfect pictures come out so cle...  \n",
       "97  The ultimate performance\\nCamera is superb\\nTh...  \n",
       "\n",
       "[98 rows x 3 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the webdriver and feeding the webaddress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross=driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating to the search bar and entering the sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]')\n",
    "search_bar.clear()\n",
    "search_bar.send_keys(\"sneakers\")\n",
    "search_button=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links of pages from which data need to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[\"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=1\",\"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=2\",\"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=3\",\"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using for loops to add data in our empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[0])\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "for i in range(0,40):\n",
    "    brand.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[1])\n",
    "y=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "\n",
    "for i in range(0,40):\n",
    "    brand.append(y[i].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[2])\n",
    "z=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "for i in range(0,40):\n",
    "    brand.append(z[i].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_description=[]\n",
    "driver.get(links[0])\n",
    "x=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "for i in range(0,34):\n",
    "    product_description.append(x[i].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[1])\n",
    "y=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "for i in range(0,34):\n",
    "    product_description.append(y[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[2])\n",
    "z=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "for i in range(0,34):\n",
    "    product_description.append(z[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "price=[]\n",
    "driver.get(links[0])\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "\n",
    "for i in range(0,40):\n",
    "    price.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[1])\n",
    "y=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "\n",
    "for i in range(0,40):\n",
    "    price.append(y[i].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[2])\n",
    "z=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "\n",
    "for i in range(0,40):\n",
    "    price.append(z[i].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount=[]\n",
    "driver.get(links[0])\n",
    "x=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "for i in range(0,40):\n",
    "    discount.append(x[i].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[1])\n",
    "y=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "for i in range(0,39):\n",
    "    discount.append(y[i].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[2])\n",
    "z=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "for i in range(0,40):\n",
    "    discount.append(z[i].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=brand[0:101]\n",
    "product_description=product_description[0:101]\n",
    "price=price[0:101]\n",
    "discount=discount[0:101]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sneakers=pd.DataFrame({\"Brand Name\":brand,\"Product Description\":product_description,\"Price\":price,\"Discount\":discount})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹494</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹378</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Unique &amp; Perfect Collection Combo Pack of 02 S...</td>\n",
       "      <td>₹420</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>5011-Latest Collection Stylish Casual Loafer S...</td>\n",
       "      <td>₹240</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>LEBRON 2.0 Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Zorth</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹448</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹630</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>India hub</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>SM-675 Sneakers For Men</td>\n",
       "      <td>₹536</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand Name                                Product Description  \\\n",
       "0                  Echor  Luxury Fashionable casual sneaker shoes Sneake...   \n",
       "1                 Labbin                                   Sneakers For Men   \n",
       "2                Numenzo                                   Sneakers For Men   \n",
       "3                 Chevit  Unique & Perfect Collection Combo Pack of 02 S...   \n",
       "4    World Wear Footwear  5011-Latest Collection Stylish Casual Loafer S...   \n",
       "..                   ...                                                ...   \n",
       "96             bluemaker                        LEBRON 2.0 Sneakers For Men   \n",
       "97                 Zorth                                   Sneakers For Men   \n",
       "98                 SPARX  Original Luxury Branded Fashionable Men's Casu...   \n",
       "99             India hub  Casual Sneakers Shoes For Men Sneakers For Men...   \n",
       "100               Chevit                            SM-675 Sneakers For Men   \n",
       "\n",
       "    Price Discount  \n",
       "0    ₹494  80% off  \n",
       "1    ₹399  50% off  \n",
       "2    ₹378  62% off  \n",
       "3    ₹420  71% off  \n",
       "4    ₹240  51% off  \n",
       "..    ...      ...  \n",
       "96   ₹399  55% off  \n",
       "97   ₹448  15% off  \n",
       "98   ₹630  40% off  \n",
       "99   ₹399  58% off  \n",
       "100  ₹536  88% off  \n",
       "\n",
       "[101 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the driver and entering the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.myntra.com/shoes\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "shoe_desc=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a list of links through which data need to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[\"https://www.myntra.com/shoes?plaEnabled=false\",\"https://www.myntra.com/shoes?p=2&plaEnabled=false\",\"https://www.myntra.com/shoes?p=3&plaEnabled=false\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the data from website and adding to lists by means of for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[0])\n",
    "x=driver.find_elements_by_xpath('//span[@class=\"product-discountedPrice\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,33):\n",
    "    price.append(x[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[1])\n",
    "y=driver.find_elements_by_xpath('//span[@class=\"product-discountedPrice\"]')\n",
    "\n",
    "for i in range(0,37):\n",
    "    price.append(y[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[2])\n",
    "z=driver.find_elements_by_xpath('//span[@class=\"product-discountedPrice\"]')\n",
    "\n",
    "for i in range(0,37):\n",
    "    price.append(z[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "driver.get(links[0])\n",
    "x=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "\n",
    "for i in range (0,37):\n",
    "    brand.append(x[i].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[1])\n",
    "y=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "\n",
    "for i in range (0,37):\n",
    "    brand.append(y[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[2])\n",
    "z=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "\n",
    "for i in range (0,37):\n",
    "    brand.append(z[i].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[0])\n",
    "x=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "\n",
    "for i in range (0,37):\n",
    "    shoe_desc.append(x[i].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[1])\n",
    "y=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "\n",
    "for i in range (0,37):\n",
    "    shoe_desc.append(y[i].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(links[2])\n",
    "z=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "\n",
    "for i in range (0,37):\n",
    "    shoe_desc.append(z[i].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing the lists to contain 100 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=brand[0:100]\n",
    "price=price[0:100]\n",
    "shoe_desc=shoe_desc[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_myntra=pd.DataFrame({\"Brand\":brand,\"Price\":price,\"Descripton\":shoe_desc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Descripton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newfeel By Decathlon</td>\n",
       "      <td>Rs. 685</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Rs. 649</td>\n",
       "      <td>Men Solid Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.S. Polo Assn.</td>\n",
       "      <td>Rs. 649</td>\n",
       "      <td>Men Colourblocked Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 999</td>\n",
       "      <td>Men Flexracer 20 IDP Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MENGLER</td>\n",
       "      <td>Rs. 847</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 699</td>\n",
       "      <td>Men Textured Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Shezone</td>\n",
       "      <td>Rs. 1049</td>\n",
       "      <td>Women Slip-On Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Newfeel By Decathlon</td>\n",
       "      <td>Rs. 829</td>\n",
       "      <td>Men JORDAN WHY NOT ZER0 Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Provogue</td>\n",
       "      <td>Rs. 1639</td>\n",
       "      <td>Running Propel EL IDP Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Rs. 1031</td>\n",
       "      <td>Women Open Toe Flats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Brand     Price                          Descripton\n",
       "0    Newfeel By Decathlon   Rs. 685                   Men Walking Shoes\n",
       "1              HIGHLANDER   Rs. 649                  Men Solid Sneakers\n",
       "2         U.S. Polo Assn.   Rs. 649          Men Colourblocked Sneakers\n",
       "3                    Puma   Rs. 999  Men Flexracer 20 IDP Running Shoes\n",
       "4                 MENGLER   Rs. 847                   Men Walking Shoes\n",
       "..                    ...       ...                                 ...\n",
       "95                   Puma   Rs. 699               Men Textured Sneakers\n",
       "96                Shezone  Rs. 1049              Women Slip-On Sneakers\n",
       "97   Newfeel By Decathlon   Rs. 829       Men JORDAN WHY NOT ZER0 Shoes\n",
       "98               Provogue  Rs. 1639         Running Propel EL IDP Shoes\n",
       "99  HRX by Hrithik Roshan  Rs. 1031                Women Open Toe Flats\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_myntra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the webdriver and entering the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.amazon.in/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating to the searchbar and feeding the value then clicking the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar.clear()\n",
    "search_bar.send_keys(\"Laptop\")\n",
    "search_button=driver.find_element_by_xpath('//input[@id=\"nav-search-submit-button\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_7=driver.find_element_by_xpath('//li[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]//i[@class=\"a-icon a-icon-checkbox\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_9=driver.find_element_by_xpath('//li[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]//i[@class=\"a-icon a-icon-checkbox\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "rating=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the data from website and adding data to the lists using for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "rate=driver.find_elements_by_xpath('//span[@class=\"a-size-base\"]')\n",
    "pri=driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    title.append(name[i].text)\n",
    "    \n",
    "for i in range(0,10):\n",
    "    rating.append(rate[i].text)\n",
    "    \n",
    "for i in range(0,10):\n",
    "    price.append(pri[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=title[0:10]\n",
    "rating=rating[0:10]\n",
    "price=price[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataframe by using the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_laptop=pd.DataFrame({\"Title\":title,\"Rating\":rating,\"Price\":price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>1,024</td>\n",
       "      <td>59,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7-1165G7 14...</td>\n",
       "      <td>35</td>\n",
       "      <td>1,03,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>257</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>22</td>\n",
       "      <td>29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>1,024</td>\n",
       "      <td>59,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F15 (2020), 15.6-inch (39.62 c...</td>\n",
       "      <td>2</td>\n",
       "      <td>71,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>61</td>\n",
       "      <td>34,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NEXSTGO Primus NX201 NP15N1IN008P 15.6-inch La...</td>\n",
       "      <td>3</td>\n",
       "      <td>56,155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OMEN 17 Gaming Laptop, NVIDIA GeForce RTX 2070...</td>\n",
       "      <td>106</td>\n",
       "      <td>94,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell 14 (2021) i7-1165G7 2in1 Touch Screen Lap...</td>\n",
       "      <td>25</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating     Price\n",
       "0  Mi Notebook Horizon Edition 14 Intel Core i7-1...  1,024    59,999\n",
       "1  Lenovo Yoga 7 11th Gen Intel Core i7-1165G7 14...     35  1,03,890\n",
       "2  HP Pavilion (2021) Thin & Light 11th Gen Core ...    257    84,990\n",
       "3  Life Digital Laptop 15.6-inch (39.62 cms) (Int...     22    29,990\n",
       "4  Mi Notebook Horizon Edition 14 Intel Core i7-1...  1,024    59,999\n",
       "5  ASUS TUF Gaming F15 (2020), 15.6-inch (39.62 c...      2    71,990\n",
       "6  Life Digital Laptop 15.6-inch (39.62 cms) (Int...     61    34,990\n",
       "7  NEXSTGO Primus NX201 NP15N1IN008P 15.6-inch La...      3    56,155\n",
       "8  OMEN 17 Gaming Laptop, NVIDIA GeForce RTX 2070...    106    94,400\n",
       "9  Dell 14 (2021) i7-1165G7 2in1 Touch Screen Lap...     25    89,990"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
